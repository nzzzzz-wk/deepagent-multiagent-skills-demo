# API Keys for deepagents demo (OpenAI Compatible Format)

# Required: OpenAI API Key
# For local servers (Ollama, LM Studio, etc.), use 'dummy' or any value
OPENAI_API_KEY=dummy

# Required: Base URL for OpenAI compatible API server
# Examples:
#   - Ollama: http://localhost:11434/v1
#   - LM Studio: http://localhost:1234/v1
#   - LocalAI: http://localhost:8080/v1
#   - Azure: https://{resource-name}.openai.azure.com/openai/deployments/{deployment-name}
OPENAI_BASE_URL=http://localhost:11434/v1

# Model name (depends on your local server)
# Examples:
#   - Ollama: qwen2.5:7b-instruct, llama3.2, llama3.1:70b, mistral
#   - LM Studio: llama3.2, codellama, etc.
# Note: qwen2.5 supports tool calling for full multi-agent functionality
OPENAI_MODEL=qwen2.5:7b-instruct

# Optional: LangSmith for tracing (https://smith.langchain.com)
LANGSMITH_API_KEY=your_langsmith_api_key_here

# =============================================================================
# Vector Database Configuration (for RAG Workflow)
# =============================================================================

# Vector DB provider: chroma, milvus
VECTOR_DB_PROVIDER=chroma

# Collection name for vector storage
VECTOR_DB_COLLECTION=documents

# ChromaDB local storage directory
VECTOR_DB_PERSIST_DIR=./chroma_db

# Milvus connection URI (for cloud services like ZetaCloud)
# Example: https://your-cluster-id.gcp.cloud.zilliz.com
VECTOR_DB_URI=

# API key for cloud vector DB services
VECTOR_DB_API_KEY=

# Embedding model for vectorization
EMBEDDING_MODEL=text-embedding-3-small

# Number of results to retrieve
VECTOR_DB_TOP_K=5
